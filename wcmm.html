<!DOCTYPE html>
<html>

  <head>
    <meta charset="UTF-8"/>
    <title>Wcmm - Water color melody machine</title>
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1" /> -->
    <!-- Agrega estos datos entre las etiquetas <head> de tu sitio -->
    <meta name="description" content="Wcmm - Water color melody machine"/>

    <meta name="twitter:card" value="Que el intérprete sea sensible y te genere emociones es cosa tuya, el solo quiere contar historias, te ofrece cuatro con un resultado único e irrepetible. En tus manos está escuchar cada historia de forma independiente o mezclarlas entre sí."/>

    <meta property="og:title" content="Wcmm - Water color melody machine"/>
    <meta property="og:type" content="article"/>
    <meta property="og:url" content="http://wcmm.bikolabs.io//"/>
    <meta property="og:image" content="http://www.ejemplo.com/imagen.jpg"/>
    <meta property="og:description" content=" Wcmm - Water color melody machine"/>
    <link rel="stylesheet" href="style.css"/>
  </head>

  <body>
    <div class="wcmm--wrap">
      <div id="container">
        <div id="keyboard" class="hidden"></div>
        <div class="point"></div>
      </div>

      <div id="status">
        <div class="d-flex flex-column align-items-center">
          <div class="spinner-border spinner-color-white" role="status">
            <span class="sr-only">Loading...</span>
          </div>
        </div>
      </div>

      <div id="canvas"></div>

      <div class="machine--control fixed-bottom d-flex align-items-center justify-content-between">
        <div class="machine--control__logo">
          <a href="/"><img src="assets/images/wcmm-min.png" alt="wcmm"/></a>
        </div>
        <div class="machine--control__select">
          <div class="d-flex justify-content-center">
            <!-- <div class="selection--item"> <a href="#menor" class="btn-sel"><img src="assets/images/icon-moon-min.svg" alt="Moon"/></a> </div> <div class="selection--item"> <a href="#mayor" class="btn-sel"><img src="assets/images/icon-sun-min.svg" alt="Sun"/></a> </div> <div class="selection--item"> <a href="#oriental" class="btn-sel"><img src="assets/images/icon-mountain-min.svg" alt="Mountain"/></a> </div> <div class="selection--item"> <a href="#binario" class="btn-sel"><img src=" assets/images/icon-binary-min.svg" alt="Binary"/></a> </div> -->
            <div class="selection--item">
              <a href="#menor" class="btn-sel"><img src="assets/images/icon-moon-min.svg" alt="Moon"/></a>
              <a href="#mayor" class="btn-sel"><img src="assets/images/icon-sun-min.svg" alt="Sun"/></a>
              <a href="#oriental" class="btn-sel"><img src="assets/images/icon-mountain-min.svg" alt="Mountain"/></a>
              <a href="#binario" class="btn-sel"><img src=" assets/images/icon-binary-min.svg" alt="Binary"/></a>
            </div>

          </div>
        </div>
        <div class="machine--control__links d-flex justify-content-end px-4">
          <div class="pr-4" onclick="return false;" id="downloadCanvas">
            <a href="javascript:void(0)" class="machine--control__btn-down">Download canvas</a>
          </div>
          <div class="pr-2">
            <div class="menu--action">
              <a href="" class="machine--control__btn">Reset</a>
            </div>
          </div>
          <div class="pr-2">
            <div class="menu--action ">
              <a href="#" class="machine--control__btn">About EN</a>
            </div>
          </div>
          <div>
            <div class="menu--action__es">
              <a href="#" class="machine--control__btn">About ES</a>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!--Overlay ES -->
    <div class="fullscreen-page__es">
      <div class="post--header d-flex justify-content-between align-items-center sticky-top">
        <div>
          <img src="/assets/images/wcmm-min.png" alt="Wcmm"/>
        </div>
        <div class="menu--action__es pr-2">
          <img src="assets/images/close.png" alt="Cerrar"/>
        </div>
      </div>

      <div class="container">
        <div class="row">
          <div class="col-md-10 offset-md-1 post--content">
            <h2 class="title--base pb-4">Code</h2>
            <p>
              <a href="https://github.com/karlosgliberal/watercolormelodymachine">
                The code of project wcmm
              </a>
            </p>
            <h2 class="title--base pb-4">About</h2>
            <p>
              ¿Que posibilidades creativas ofrece el machine learning? WCMM es un proceso creativo usando Machine learning. Está maquina es una inteligencia artificial que improvisa al piano mientras pinta.
            </p>
            <p>
              Para crear WCMM hemos usado
              <a href="https://magenta.tensorflow.org/">Magenta</a>
              que es un proyecto de investigación de código abierto que explora el papel del aprendizaje automático como herramienta creativa.
            </p>

            <p>
              Llevamos tiempo trabajando con machine learning para nuestros proyectos como en el caso del
              <a href="https://ciberbarba.biko2.com">ciberbarba</a>
              o anteriormente en
              <a href="https://receteitor.interzonas.info">receteitor</a>.<br/>
              WCMM es otra aproximación a este juego.
            </p>
            <h2 class="title--base pb-4">Como funciona</h2>
            <p>
              Hemos usado performace_rnn que busca generar música teniendo en cuenta la expresividad en el tiempo y la dinámica, esta investigación ha sido creada por
              <a href="https://twitter.com/iansimon">
                iansimon</a>
              <a href="https://twitter.com/osageev">
                osageev</a>
              y aqui esta el paper del proyecto:
              <a href="https://magenta.tensorflow.org/performance-rnn">https://magenta.tensorflow.org/performance-rnn</a >
            </p>
            <p>
              La expresividad en el tiempo y la dinámica son una parte esencial de la música y esta particularidad nos hizo querer jugar con performace_rnn. Para entender la importancia de la expresividad y la dinámica escuche los siguientes dos clips de la misma pieza de Chopin, el primero de los cuales ha sido despojado de estas cualidades:
            </p>
            <div class="d-flex justify-content-around py-3">
              <div>
                <p>Chopin (quantized)</p>
                <audio src="/assets/performance_rnn/chopin-quantized.mp3" controls=""></audio>
              </div>
              <div>
                <p>
                  Chopin (performed by Sageev Oore)
                </p>
                <audio src="/assets/performance_rnn/chopin-unquantized.mp3" controls=""></audio>
              </div>
            </div>

            <p>
              La sutileza o contundencia pulsando la tecla del piano o alargando las notas es un elemento creativo con el que cuentan los pianistas para sus interpretaciones, su sensibilidad es fundamental para que podamos sentir emociones.
            </p>

            <p>
              Así que ¿Podemos crear máquinas cargadas de sensibilidad?
            </p>

            <p>
              Performace_rnn nos da la improvisación al piano. Una red neuronal recurrente (RNN) que podríamos simplificar diciendo que es una red neuronal con memoria, lo que nos aporta es que dada una serie concreta (texto, temperaturas, notas) la red neuronal nos ofrecerá el “supuesto” siguiente elemento de la serie. En nuestro caso es una nota MIDI pero con su expresividad y su dinámica, como cuando lo hace un intérprete real cuando pulsa el teclado en un piano.
            </p>

            <p>
              Performace_rnn admite una serie de ajustes, como la temperatura o la densidad de pulsación, escala y su nota tónica pero en nuestro caso esto lo delegamos en el cliente gestionado por el navegador.
            </p>
            <h2 class="title--base pb-4">Tensorflow.js - Magenta</h2>
            <p>
              En el repositorio del
              <a href="https://github.com/tensorflow/magenta/tree/master/magenta/models/performance_rnn">
                proyecto</a >
              esta el código python asi como el colab para poder experimentar con el modelo. Nosotros hemos usado un modelo pre-entrenado para usarlos con
              <a href="https://www.tensorflow.org/js">
                Tensorflow.js</a>. TensorFlow.js es una biblioteca para desarrollar y entrenar modelos ML en JavaScript, y desplegar en el navegador o en Node.js
            </p>
            <p>
              Con tensorflow.js y desde el navegador es donde cargamos el modelo RNN de Magenta y donde vamos modificando los ajustes como por ejemplo el pitch_class_histogram: Que una representación de cadena de una 12 valores que representan la frecuencia relativa de las notas de cada clase de tono, comenzando con C (Do). Por ejemplo: "[2, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1] La RNN "tenderá a adherirse a una escala de C mayor, con el doble de C que cualquiera de las otras notas de la escala.
            </p>
            <script src="https://gist.github.com/karlosgliberal/a5207cc4ff18b8c58aec1ca91d8e1d92.js"></script>

            <h2 class="title--base pb-4">Tone.js</h2>
            <p>
              Usamos
              <a href="https://tonejs.github.io/">tone.js</a>
              para poder hacer tocar al navegador y en el caso de perfromance_rnn usamos la base de sonidos de Salamander Grand Piano con el proyecto tone-piano que nos aporta esa gestión de velocidad y dinámica.
            </p>
            <h2 class="title--base pb-4">P5.js</h2>
            <p>
              WCMM nace como un proyecto de arte generativo, son muchos los artistas que están usando el machine learning para poder crear diferentes obras. Para nosotros el arte generativo es
              <i>
                Cuando el artista entra en colaboración con alguna suerte de autómata creador, y resigna el poder de decidir cada detalle de lo que sucede en la obra, ese diálogo es el que permite lo generativo.</i >
            </p>
            <p>
              Nuestro autómata es la red neuronal recurrente que toca el piano y su sensibilidad es la que usamos para crear el trazo.
            </p>
            <p>
              Para la creación visual hemos usado p5.js es uno de los proyectos más bonitos de internet, su comunidad y su posibilidades son increíbles.
            </p>
            <p>
              El trazo que con el que emulamos la acuarela funciona creando un conjunto de vértices translúcidos con una mezcla de colores específica simula a una acuarela. El proceso de experimentación para lograr el mejor trazo posible forma parte del proyecto, crear un ambiente preparado donde se de el juego y la expresión con el código es parte del proyecto, aquí se puede ver algunos de los experimentos.
            </p>

            <img src="/assets/images/imagenProcesoTrazo.png" alt="Ejemplo" class="img-fluid"/>
            <p>
              Con el trazo resuelto el siguiente elemento era relacionar la improvisación del performance_rnn con este trazo, que cada nota enviada desde tensorflow.js, genere una animación y que esta se vea representada por las características de la nota el momento y la dinámica de la misma.
            </p>
            <p>
              Esto en combinación con las escalas nos permiten crear las historias y luego combinarlas entre sí creando lienzos únicos en cada visionado.
            </p>
            <h2 class="title--base pb-4">Autores</h2>
            <p>
              Creador por
              <a href="https://medium.com/@patxangas">Karlos G Libreal @patxangas</a >
              y realizado con la ayuda como siempre de
              <a href="https://twitter.com/aitor_rl">Aitor Resano</a>,
              <a href="https://twitter.com/merisu">
                Miren Arrese</a>
              y
              <a href="https://twitter.com/oierbravo">
                Oier bravo</a>.
            </p>

            <h2 class="title--base pb-4">Bikolabs</h2>
            <p>
              Es el
              <a href="https://www.biko2.com/bikolabs-creatividad-pirata/">
                laboratorio de especulación
              </a >de
              <a href="https://www.biko2.com">
                Biko
              </a>buscamos en las periferias creativas nueva experiencias y nuevos mestizajes para poder ver 20 minutos por delante.
            </p>
            <h2 class="title--base pb-4">Inspiración</h2>
            <p>
              El arte digital o generativo es como un rizoma donde todo se entrelaza creando nodos fuertes o débiles pero que en su conjunto crean una red compleja y basta en matices. Este proyecto tiene muchas inspiraciones pero estas eran obligadas de mencionar.
              <a href="https://medium.com/@zachlieberman/daily-sketches-in-2017-1b4234b0615d">
                @zachlieberman
              </a >Explicando su proceso creativo diario me inspiró para buscar el mío propio
              <a href="https://twitter.com/kolorexpresion">
                Iñaki zalba</a>
              con su visión del juego y los espacios preparados. Kjetil Golid con su
              <a href="https://generated.space/">https://generated.space/</a>
              sus codigos son fudamentales para el arte generativo y la base inicial del trazo
            </p>
          </div>
        </div>
      </div>
    </div>
    <!--End Overlay -->

    <!-- Overlay About -->
    <div class="fullscreen-page">
      <div class="post--header d-flex justify-content-between align-items-center sticky-top">
        <div>
          <img src="/assets/images/wcmm-min.png" alt="Wcmm"/>
        </div>
        <div class="menu--action pr-2">
          <img src="assets/images/close.png" alt="Cerrar"/>
        </div>
      </div>
      <div class="container">
        <div class="row">
          <div class="col-md-10 offset-md-1 post--content">
            <h2 class="title--base pb-4">Code</h2>
            <p>
              <a href="https://github.com/karlosgliberal/watercolormelodymachine">
                The code of project wcmm
              </a>
            </p>
            <h2 class="title--base pb-4">About</h2>
            <p>
              What creative possibilities does machine learning offer?
              <br/>
              WCMM is a creative process using Machine learning. This machine is an artificial intelligence that improvises at the piano while painting.
            </p>
            <p>
              WCMM its made with
              <a href="https://magenta.tensorflow.org/">Magenta</a>, an open-source research project that explores the role of the machine learning as a creative tool.
            </p>

            <p>
              We have been working with machine learning for some time now for our projects as in the case of the
              <a href="https://ciberbarba.biko2.com">ciberbarba</a>
              or previously in
              <a href="https://receteitor.interzonas.info">receitor
              </a>.<br/>
              WCMM is another approach to this game.
            </p>
            <h2 class="title--base pb-4">How it works</h2>
            <p>
              We have used performace_rnn that seeks to generate music taking care of the expressiveness in time and dynamics. This research has been created by
              <a href="https://twitter.com/iansimon">
                iansimon</a>
              <a href="https://twitter.com/osageev">
                osageev</a>
              and here it is. paper of the project:
              <a href="https://magenta.tensorflow.org/performance-rnn">https://magenta.tensorflow.org/performance-rnn</a >
            </p>
            <p>
              Expressiveness in time and dynamics are an essential part of music and this particularity made us want to play with performace_rnn. To understand the importance of expressiveness and dynamics listen to the following two clips from the same piece of Chopin,the first of whom has been stripped of these qualities:
            </p>
            <div class="d-flex justify-content-around py-3">
              <div>
                <p>Chopin (quantized)</p>
                <audio src="/assets/performance_rnn/chopin-quantized.mp3" controls=""></audio>
              </div>
              <div>
                <p>
                  Chopin (performed by Sageev Oore)
                </p>
                <audio src="/assets/performance_rnn/chopin-unquantized.mp3" controls=""></audio>
              </div>
            </div>

            <p>
              Subtlety or forcefulness by pressing the piano key or lengthening notes is a creative element that pianists count on for your interpretations, your sensitivity is fundamental so that we can feel emotions.
            </p>

            <p>
              So can we create machines loaded with sensitivity?
            </p>

            <p>
              Performace_rnn gives us an improvisation at the piano. A neural network (RNN) that we could simplify by saying that it is a network. neuronal with memory, what it gives us is that given a series of concrete (text, temperatures, notes) the neural network will offer us the next "supposed" element in the series. In our case it is a MIDI note but with its expressiveness and its dynamics, as when a real interpreter does when he presses the keyboard on a piano.
            </p>

            <p>
              Performace_rnn supports a number of settings, such as temperature or the density of pulsation, scale and its tonic note but in our If this is delegated to the client managed by the browser.
            </p>
            <h2 class="title--base pb-4">Tensorflow.js - Magenta</h2>
            <p>
              In the repository of the
              <a href="https://github.com/tensorflow/magenta/tree/master/magenta/models/performance_rnn">
                proyecto</a >
              there is the python code as well as the colab to be able to experiment with the model. We have used a pre-trained model to use them with
              <a href="https://www.tensorflow.org/js">
                Tensorflow.js</a>. TensorFlow.js is a library for developing and training ML models in JavaScript, and display in the browser or in Node.js
            </p>
            <p>
              With tensorflow.js and from the browser is where we load the model RNN of Magenta and where we are modifying the settings as for example the pitch_class_histogram: That a string representation of a 12 values representing the relative frequency of the notes for each tone class, beginning with C (C). For example: 2, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1] The RNN "will tend to adhere". to a scale of C greater, with twice as much C as any of the others. other notes on the scale.
            </p>
            <script src="https://gist.github.com/karlosgliberal/a5207cc4ff18b8c58aec1ca91d8e1d92.js"></script>

            <h2 class="title--base pb-4">Tone.js</h2>
            <p>
              We use
              <a href="https://tonejs.github.io/">tone.js</a>
              to be able to play in the browser and in the case of perfromance_rnn we use the sound base of Salamander Grand Piano with the project tone-piano that gives us the management of speed and dynamics.
            </p>
            <h2 class="title--base pb-4">P5.js</h2>
            <p>
              WCMM is born as a project of generative art, there are many artists who are using machine learning in order to be able to create different works. For us generative art is
              <i>
                When the artist enters into collaboration with some sort of automaton, and resigns the power to decide every single detail of the what happens in the work, that dialogue is the one that allows the generative.</i >
            </p>
            <p>
              Our automaton is the recurrent neural network that plays the piano and his sensitivity is what we use to create the stroke.
            </p>
            <p>
              For the visual creation we have used p5.js is one of the projects of the internet, your community and your possibilities are unbelievable.
            </p>
            <p>
              The line with which we emulate the watercolor works by creating a set of translucent vertices with a mixture of colours simulates a watercolor. The process of experimentation to achieve the best possible stroke is part of the project, create a prepared environment where you can play and express yourself with the code is part of the project, here you can see some of the experiments.
            </p>

            <img src="/assets/images/imagenProcesoTrazo.png" alt="Ejemplo" class="img-fluid"/>
            <p>
              With the stroke resolved the following element was to relate the improvisation of the performance_rnn with this stroke, that each note sent from tensorflow.js, generate an animation and that this one is is represented by the characteristics of the note the moment and the dynamics of it.
            </p>
            <p>
              This in combination with the scales allow us to create the stories and then combine them with each other to create unique canvases in every viewing.
            </p>
            <h2 class="title--base pb-4">Autors</h2>
            <p>
              Created by
              <a href="https://medium.com/@patxangas">Karlos G Libreal @patxangas</a >
              and carried out with the help, as always, ofe
              <a href="https://twitter.com/aitor_rl">Aitor Resano</a>,
              <a href="https://twitter.com/merisu">
                Miren Arrese</a>
              y
              <a href="https://twitter.com/oierbravo">
                Oier bravo</a>.
            </p>

            <h2 class="title--base pb-4">Bikolabs</h2>
            <p>
              It's the
              <a href="https://www.biko2.com/bikolabs-creatividad-pirata/">
                speculation laboratory
              </a >from
              <a href="https://www.biko2.com">
                Biko
              </a>we search in the creative peripheries new experiences and new crossbreeds for to be able to see 20 minutes ahead.
            </p>
            <h2 class="title--base pb-4">Inspiration</h2>
            <p>
              The digital or generative art is like a rhizome where everything is it intertwines creating strong or weak nodes but which as a whole they create a complex network and it is enough in nuances. This project has many inspirations but these were bound to mention.
              <a href="https://medium.com/@zachlieberman/daily-sketches-in-2017-1b4234b0615d">
                @zachlieberman
              </a >Explaining his daily creative process inspired me to seek the my own
              <a href="https://twitter.com/kolorexpresion">
                Iñaki zalba</a>
              with his vision of the game and the spaces prepared. Kjetil Golid with his
              <a href="https://generated.space/">https://generated.space/
              </a>
              their codes are fundamental to generative art and the basis of the initial stroke
            </p>
          </div>
        </div>
      </div>
    </div>

    <!--Fin Overlay ES -->

    <script src="main.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <!-- Custom Overlay -->
    <script>
      (function () {
        $('.menu--action').on('click', function () {
          $(this).toggleClass('open');
          $('.fullscreen-page').toggleClass('open');
          $('.wcmm--wrap').toggleClass('open');
          return $(this).toggleClass('active');
        });
      }.call(this));
      (function () {
        $('.menu--action__es').on('click', function () {
          $(this).toggleClass('open');
          $('.fullscreen-page__es').toggleClass('open');
          $('.wcmm--wrap').toggleClass('open');
          return $(this).toggleClass('active');
        });
      }.call(this));
    </script>
    <!-- Fin Custom Overlay -->
    <script>
      $(document).ready(function () {
        $(".btn-sel").click(function () {
          $(this)
            .addClass("btn-sel__active")
            .siblings()
            .removeClass("btn-sel__active");
        });
      });
    </script>

  </body>
</html>
